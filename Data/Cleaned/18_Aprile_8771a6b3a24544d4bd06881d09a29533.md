# 18 Aprile

Argomenti: Coefficiente di Pearson, Colinearità delle caratteristiche, Covarianza
.: Yes

## Colinearità delle caratteristiche

La `colinearità` indica se esiste una relazione lineare tra 2 variabili, nel caso di `multilinearità` quando la relazione si estende a più di 2 variabili.

$$
(1\cdot X_{q_1})+
          (2\cdot X_{q_2})+
          (1\cdot X_{q_3})
$$

Si suppone di avere 3 features $\left\{F_1,F_2,F_3\right\}$, con pesi corrispondenti $\left\{1,2,3\right\}$, se si ottiene una nuova istanza $X_q=\left\{X_{q_1},X_{q_2},X_{q_3}\right\}$ si ottiene $W^{*T}X_q$

$$
F_2=1.5\cdot F_1
$$

Supponendo che ci sia questa correlazione

$$
(4\cdot X_{q_1})+(3\cdot X_{q_3})
$$

Si ottiene che $W^{*T}X_q$ si può riscrivere in questo modo

$$
W^*=\left[1,2,3\right]\\
W^{**}=\left[4,0,3\right]
$$

Naturalmente se vengono confrontati i vettori dei pesi dalle 2 equazioni si notano che sono diversi. Comunque i 2 vettori dei pesi daranno lo stesso output.

Variabili indipendenti correlate implicano che è impossibile mantenere costante una variabile mentre se ne varia l’altra e viceversa.

## Approcci per stimare la colinearità

Sono spesso basati sulle seguenti misure: `covarianza`, `correlazione di Pearson`, `correlazione Tau di Kendall`, `correlazione per ranghi di Spearman`. Date queste misure si costruisce una matrice di correlazione, che mostra l’intensità di correlazione tra ogni coppia di caratteristiche.

## Covarianza

La matrice di correlazione può essere costruita valutando la covarianza per ogni coppia di valori assoluti da 2 caratteristiche distinte $X$ e $Y$ per ogni istanza estratta dei dati:

$$
Cov(X,Y)=E((X\mu_X)(Y\mu_Y))
$$

Valori maggiore di 0 indicano la proporzionalità lineare, minori di 0 indicano la proporzionalità inversa mentre uguale a 0 per indipendenza lineare.

Si può avere covarianza pari a 0 anche per variabili non indipendenti, nel caso di associazioni di tipo non lineari.

## Coefficiente di Pearson

Il problema della covarianza è che è influenzata dai valori assoluti delle variabili, come mostrato in questo esempio:

$$
\left[1,2,3\right],\left[4,6,10\right]\to Cov(X,Y)=2\\
\left[10,20,30\right],\left[40,60,100\right]\to Cov(X,Y)=200
$$

$$
\rho_{X,Y}=\dfrac{Cov(X,Y)}{\sigma_x,\sigma_y}
$$

Quello che fa il coefficiente di pearson è dividere la covarianza per (chiedere ad alberto)

Questo coefficiente assume valori nell’intervallo $\left[-1,1\right]$, cioè da pefetta correlazione negativa a perfetta correlazione positiva. Per valore uguale a 0 indica l’assenza di correlazione lineare.

## Correlazione Tau di Kendall

Questa metrica viene utilizzata quando ai dati viene associato un grado.

$$
\tau=\dfrac{C-D}{C+D}
$$

Questo valore è compreso nell’intervallo $\left[0,1\right]$, si calcola con il numero di coppie equivalenti tra loro ($C$) e il numero di coppie con valori di grado discordanti ($D$)

## Correlazione per ranghi di Spearman

Stima una misura di `monotonicità` della relazione tra 2 variabili.

$$
\rho=\dfrac{6\sum_id_i^2}{N(N^2-1)}
$$

Dove $d_i$ indica la differenza tra 2 gradi su una osservazione.